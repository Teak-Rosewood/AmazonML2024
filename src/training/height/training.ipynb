{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 17:20:39.253534: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-13 17:20:39.264418: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-13 17:20:39.276571: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-13 17:20:39.280048: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-13 17:20:39.289664: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-13 17:20:39.910124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726228240.585487  137077 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726228240.611247  137077 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726228240.611404  137077 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726228240.613121  137077 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726228240.613226  137077 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726228240.613298  137077 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726228240.663346  137077 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726228240.663463  137077 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726228240.663538  137077 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-13 17:20:40.663606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1182 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 1000\n",
    "MAX_SEQ_LEN = 100\n",
    "IMAGE_SIZE = (224, 224)\n",
    "VOCAB_SIZE = 10000\n",
    "\n",
    "# Load CSV\n",
    "data = pd.read_csv('height_with_ocr.csv')\n",
    "\n",
    "# Handle missing values\n",
    "data = data.dropna(subset=['ocr_text', 'numeric_value', 'unit'])\n",
    "\n",
    "# Calculate min and max values for normalization\n",
    "numeric_min = data['numeric_value'].min()\n",
    "numeric_max = data['numeric_value'].max()\n",
    "\n",
    "def normalize_numeric_value(value, min_value, max_value):\n",
    "    return (value - min_value) / (max_value - min_value)\n",
    "\n",
    "# Build tokenizer and preprocess text\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(data['ocr_text'])\n",
    "\n",
    "# Build StringLookup layer for entity classes\n",
    "unit_classes = data['unit'].unique()\n",
    "string_lookup = tf.keras.layers.StringLookup(vocabulary=unit_classes)\n",
    "\n",
    "def preprocess_text(ocr_text):\n",
    "    ocr_text = ocr_text.numpy().decode('utf-8')  # Ensure the input is a string\n",
    "    tokenized_text = tokenizer.texts_to_sequences([ocr_text])\n",
    "    padded_text = pad_sequences(tokenized_text, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "    return np.array(padded_text[0], dtype=np.int32) \n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "def preprocess_data(image_path, ocr_text, numeric_value, unit_class):\n",
    "    image = preprocess_image(image_path)\n",
    "    ocr_text = tf.py_function(preprocess_text, [ocr_text], tf.int32)  # Ensure output is int32\n",
    "    ocr_text.set_shape([MAX_SEQ_LEN])  # Set the shape explicitly\n",
    "\n",
    "    numeric_value_normalized = normalize_numeric_value(numeric_value, numeric_min, numeric_max)\n",
    "    numeric_value_normalized = tf.expand_dims(numeric_value_normalized, axis=-1)  # Ensure scalar for numeric_value\n",
    "\n",
    "    unit_class = string_lookup(unit_class)\n",
    "    return (image, ocr_text), (numeric_value_normalized, unit_class)\n",
    "\n",
    "def load_dataset(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    data = data.dropna(subset=['ocr_text', 'numeric_value', 'unit'])  # Drop rows with NaN values\n",
    "    image_paths = data['id'].apply(lambda x: f'datasets/{x}.jpg').values\n",
    "    ocr_texts = data['ocr_text'].values\n",
    "    numeric_values = data['numeric_value'].values.astype(np.float32)\n",
    "    unit_classes = data['unit'].values\n",
    "    return image_paths, ocr_texts, numeric_values, unit_classes\n",
    "\n",
    "def create_tf_dataset(image_paths, ocr_texts, numeric_values, unit_classes):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, ocr_texts, numeric_values, unit_classes))\n",
    "    dataset = dataset.map(lambda image_path, ocr_text, numeric_value, unit_class: (\n",
    "        (image_path, ocr_text), (numeric_value, unit_class)\n",
    "    ))\n",
    "    dataset = dataset.map(lambda inputs, targets: preprocess_data(inputs[0], inputs[1], targets[0], targets[1]), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.filter(lambda inputs, targets: inputs is not None and targets is not None)\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Load data\n",
    "image_paths, ocr_texts, numeric_values, unit_classes = load_dataset('height_with_ocr.csv')\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_size = int(0.8 * len(image_paths))\n",
    "train_image_paths = image_paths[:train_size]\n",
    "train_ocr_texts = ocr_texts[:train_size]\n",
    "train_numeric_values = numeric_values[:train_size]\n",
    "train_unit_classes = unit_classes[:train_size]\n",
    "\n",
    "val_image_paths = image_paths[train_size:]\n",
    "val_ocr_texts = ocr_texts[train_size:]\n",
    "val_numeric_values = numeric_values[train_size:]\n",
    "val_unit_classes = unit_classes[train_size:]\n",
    "\n",
    "train_dataset = create_tf_dataset(train_image_paths, train_ocr_texts, train_numeric_values, train_unit_classes)\n",
    "val_dataset = create_tf_dataset(val_image_paths, val_ocr_texts, val_numeric_values, val_unit_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Embedding, GlobalAveragePooling1D, GlobalAveragePooling2D, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError, SparseCategoricalCrossentropy\n",
    "\n",
    "# Load ResNet model\n",
    "resnet_model = ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=IMAGE_SIZE + (3,)\n",
    ")\n",
    "\n",
    "# Freeze the ResNet model\n",
    "resnet_model.trainable = False\n",
    "\n",
    "# Image input\n",
    "image_input = Input(shape=IMAGE_SIZE + (3,), name='image_input')\n",
    "image_features = resnet_model(image_input)\n",
    "image_features = GlobalAveragePooling2D()(image_features)\n",
    "\n",
    "# Text input\n",
    "text_input = Input(shape=(MAX_SEQ_LEN,), name='text_input')\n",
    "text_embedding = Embedding(input_dim=VOCAB_SIZE, output_dim=128)(text_input)\n",
    "text_features = GlobalAveragePooling1D()(text_embedding)\n",
    "\n",
    "# Concatenate image and text features\n",
    "combined_features = Concatenate()([image_features, text_features])\n",
    "\n",
    "# Output layers\n",
    "numeric_output = Dense(1, name='numeric_output')(combined_features)\n",
    "unit_output = Dense(len(np.unique(unit_classes)), activation='softmax', name='unit_output')(combined_features)\n",
    "\n",
    "# Define custom loss function\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \n",
    "    numeric_loss = MeanSquaredError()(y_true[0], y_pred[0])\n",
    "    unit_loss = SparseCategoricalCrossentropy()(y_true[1], y_pred[1])\n",
    "    \n",
    "    return numeric_loss + unit_loss\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[image_input, text_input], outputs=[numeric_output, unit_output])\n",
    "\n",
    "# Compile the model with custom loss function\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), \n",
    "              loss=custom_loss,\n",
    "              metrics={'numeric_output': 'mae', 'unit_output': 'accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.18 6.5  9.2  ... 2.8  9.   8.66]\n"
     ]
    }
   ],
   "source": [
    "print(train_numeric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726228245.962749  137229 service.cc:146] XLA service 0x76d02004d960 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1726228245.962773  137229 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-09-13 17:20:46.079156: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-13 17:20:46.712451: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3/Unknown \u001b[1m9s\u001b[0m 53ms/step - loss: 2.9477 - numeric_output_loss: 1.4409 - numeric_output_mae: 1.2087 - unit_output_accuracy: 0.0000e+00 - unit_output_loss: 1.5068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1726228250.669899  137229 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    392/Unknown \u001b[1m31s\u001b[0m 59ms/step - loss: nan - numeric_output_loss: nan - numeric_output_mae: nan - unit_output_accuracy: 0.8069 - unit_output_loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 17:21:13.738065: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-09-13 17:21:13.738303: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_8]]\n",
      "/home/blank/miniconda3/envs/tf/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 90ms/step - loss: nan - numeric_output_loss: nan - numeric_output_mae: nan - unit_output_accuracy: 0.8072 - unit_output_loss: nan - val_loss: nan - val_numeric_output_loss: nan - val_numeric_output_mae: nan - val_unit_output_accuracy: 0.9879 - val_unit_output_loss: nan\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 17:21:26.030436: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-09-13 17:21:26.030485: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10595772756483887675\n",
      "2024-09-13 17:21:26.030493: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 12580291881751655384\n",
      "2024-09-13 17:21:26.030503: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 548844677129314260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m117/392\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - loss: nan - numeric_output_loss: nan - numeric_output_mae: nan - unit_output_accuracy: 0.9860 - unit_output_loss: nan"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameters\n",
    "IMAGE_SIZE = (224, 224)\n",
    "MAX_SEQ_LEN = 100\n",
    "VOCAB_SIZE = 10000\n",
    "\n",
    "# Assuming tokenizer and string_lookup are already defined\n",
    "# tokenizer = ...\n",
    "# string_lookup = ...\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "def preprocess_text(ocr_text):\n",
    "    tokenized_text = tokenizer.texts_to_sequences([ocr_text])\n",
    "    padded_text = pad_sequences(tokenized_text, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "    return padded_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, ocr_text):\n",
    "    # Preprocess the inputs\n",
    "    image = preprocess_image(image_path)\n",
    "    text = preprocess_text(ocr_text)\n",
    "    \n",
    "    # Add batch dimension\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    text = tf.expand_dims(text, axis=0)\n",
    "    \n",
    "    # Make predictions\n",
    "    numeric_prediction, unit_prediction = model.predict([image, text])\n",
    "    \n",
    "    # Post-process the outputs\n",
    "    numeric_value = numeric_prediction[0][0]  # Since it's a scalar\n",
    "    unit_class = string_lookup.get_vocabulary()[np.argmax(unit_prediction[0])]\n",
    "    \n",
    "    return numeric_value, unit_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "image_path = 'datasets/7195.jpg'\n",
    "ocr_text = 'Product Details 1 Green Aventurine 0.94\"\" Net Weight:21g'\n",
    "\n",
    "numeric_value, unit_class = predict(image_path, ocr_text)\n",
    "print(f'Predicted Numeric Value: {numeric_value}')\n",
    "print(f'Predicted Unit Class: {unit_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
