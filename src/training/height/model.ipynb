{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blank/miniconda3/envs/tf/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blank/miniconda3/envs/tf/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "text_embedding_model = TFAutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "img_embedding_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_text_model(img_embedding_model, text_embedding_model, num_classes):\n",
    "\n",
    "    text_inputs =Input(shape=(None,), dtype=tf.int32)\n",
    "    attention_mask = Input(shape=(None,), dtype=tf.int32)\n",
    "    image_inputs = Input(shape=(224, 224, 3), name=\"image_input\")\n",
    "\n",
    "    text_embeddings = text_embedding_model(text_inputs, attention_mask=attention_mask)[0]\n",
    "    image_embeddings = img_embedding_model(image_inputs)\n",
    "    image_embeddings = GlobalAveragePooling2D()(image_embeddings)\n",
    "\n",
    "    mask = tf.cast(tf.expand_dims(attention_mask, axis=-1), tf.float32)\n",
    "    text_embeddings = tf.reduce_sum(text_embeddings * mask, axis=1) / tf.clip_by_value(tf.reduce_sum(mask, axis=1), clip_value_min=1e-9, clip_value_max=tf.float32.max)\n",
    "\n",
    "    pooled_embeddings = Concatenate()([text_embeddings, image_embeddings])\n",
    "    x = Dense(256, activation='relu')(pooled_embeddings)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "\n",
    "    # Numerical Outputs (shared branch)\n",
    "    numerical_outputs = [Dense(12, activation='softmax', name=f\"numerical_output_{i}\")(x) for i in range(7)]\n",
    "\n",
    "    # Separate dense layers for unit output\n",
    "    y = Dense(64, activation='relu')(pooled_embeddings)\n",
    "    y = Dropout(0.3)(y)\n",
    "    y = Dense(32, activation='relu')(y)\n",
    "    units_output = Dense(num_classes, activation='softmax', name=\"units\")(y)\n",
    "    return tf.keras.Model(inputs=[image_inputs, text_inputs, attention_mask], outputs=numerical_outputs + [units_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import plot_model\n",
    "# model.summary()\n",
    "# plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_url = \"https://www.kaggle.com/models/spsayakpaul/vision-transformer/TensorFlow2/vit-b8-fe/1\"\n",
    "# model = hub.load(model_url)\n",
    "# tf.saved_model.save(model, \"vit_model\")\n",
    "# vit_model = tf.saved_model.load(\"vit_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric_value shape: (21756, 7)\n",
      "units_number shape: (21756, 1)\n",
      "output shape: (21756, 8)\n"
     ]
    }
   ],
   "source": [
    "img_dir = \"dataset/\"\n",
    "data = pd.read_csv(\"data/height_with_ocr.csv\")\n",
    "\n",
    "image_paths = data[\"id\"].values\n",
    "ocr_text = data[\"ocr_text\"].values.tolist()\n",
    "units= data[\"unit\"].values\n",
    "numeric_value  = data['numeric_value']\n",
    "# numeric_value = np.array(numeric_value).reshape(-1, 1)\n",
    "# scaler = MinMaxScaler(feature_range=(0, 10))\n",
    "# numeric_value = scaler.fit_transform(numeric_value)\n",
    "tokenized_input = tokenizer(ocr_text, padding=True, truncation=True, max_length=128, return_tensors='tf')\n",
    "\n",
    "reverse_mapping = {i: str(i) for i in range(0, 10)}\n",
    "reverse_mapping[10] = '.'\n",
    "reverse_mapping[11] = ''\n",
    "\n",
    "mapping = {str(i): i for i in range(0, 10)}\n",
    "mapping['.'] = 10\n",
    "mapping[' '] = 11\n",
    "\n",
    "def numeric_to_digit_sequence(numeric_value):\n",
    "    # Convert the numeric values to string tensors\n",
    "    string_value = str(numeric_value)\n",
    "    if(len(string_value) > 7):\n",
    "        string_value = string_value[:7]\n",
    "    # Initialize a list to store the encoded sequences\n",
    "    encoded_sequence = []\n",
    "    \n",
    "    for char in string_value:\n",
    "        # Encode the character as an integer value\n",
    "        encoded_value = mapping[char]\n",
    "        encoded_sequence.append(encoded_value)\n",
    "    \n",
    "    # Pad the sequence with the value representing \"no value\" if length is less than 7\n",
    "    while len(encoded_sequence) < 7:\n",
    "        encoded_sequence.append(11)\n",
    "    return encoded_sequence\n",
    "\n",
    "def digit_sequence_to_numeric(encoded_sequence):\n",
    "    # Initialize a list to store the characters for the current sequence\n",
    "    char_list = []\n",
    "    \n",
    "    # Iterate over each encoded value in the sequence\n",
    "    for encoded_value in encoded_sequence:\n",
    "        # Convert the encoded value back to the corresponding character\n",
    "        char = reverse_mapping[encoded_value]\n",
    "        char_list.append(char)\n",
    "    \n",
    "    # Join the characters to form the original string representation of the number\n",
    "    number_str = ''.join(char_list).strip()\n",
    "    \n",
    "    # Convert the string back to a numeric value\n",
    "    return number_str\n",
    "\n",
    "numeric_value = numeric_value.apply(numeric_to_digit_sequence)\n",
    "numeric_value = np.array(numeric_value.tolist())\n",
    "print(\"numeric_value shape:\", numeric_value.shape)\n",
    "\n",
    "string_lookup = tf.keras.layers.StringLookup()\n",
    "string_lookup.adapt(units)\n",
    "\n",
    "units_number = string_lookup(units)\n",
    "units_number = tf.expand_dims(units_number, axis=-1)\n",
    "print(\"units_number shape:\", units_number.shape)\n",
    "\n",
    "output = tf.concat([numeric_value, units_number], axis=-1)\n",
    "print(\"output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, token, output):\n",
    "    img_dir = 'dataset/' \n",
    "    path = tf.strings.as_string(path)\n",
    "    path = tf.strings.join([img_dir, path, '.jpg'])  \n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    img = img / 255.0  \n",
    "\n",
    "    # Split the output into numerical and units\n",
    "    numerical_labels = output[:7]  # First 7 elements for numerical outputs\n",
    "    units_label = output[7]  # 8th element for units output\n",
    "\n",
    "    # Return inputs and outputs\n",
    "    return (img, token['input_ids'], token['attention_mask']), {\n",
    "        \"units\": units_label,  # 1 output for units with 6 classes\n",
    "        \"numerical_output_0\": numerical_labels[0],  # Separate labels for each of the 7 numerical outputs\n",
    "        \"numerical_output_1\": numerical_labels[1],\n",
    "        \"numerical_output_2\": numerical_labels[2],\n",
    "        \"numerical_output_3\": numerical_labels[3],\n",
    "        \"numerical_output_4\": numerical_labels[4],\n",
    "        \"numerical_output_5\": numerical_labels[5],\n",
    "        \"numerical_output_6\": numerical_labels[6],\n",
    "    }\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_paths, tokenized_input, output))\n",
    "\n",
    "dataset = dataset.map(lambda path, token, output: load_dataset(path, token, output),\n",
    "                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
    "\n",
    "train_size = int(0.9 * len(image_paths))\n",
    "val_size = len(image_paths) - train_size\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_img_text_model(img_embedding_model, text_embedding_model, string_lookup.vocabulary_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_size // BATCH_SIZE\n",
    "\n",
    "# Define the learning rate decay function\n",
    "def lr_decay(epoch, lr):\n",
    "    decay_rate = 0.1\n",
    "    decay_step = 10\n",
    "    if epoch % decay_step == 0 and epoch:\n",
    "        return lr * decay_rate\n",
    "    return lr\n",
    "\n",
    "# Create the callbacks\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='height_2.keras',\n",
    "    save_freq=steps_per_epoch * 2  # Save every 2 epochs\n",
    ")\n",
    "\n",
    "lr_scheduler_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay)\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    \"units\": \"sparse_categorical_crossentropy\",  # For the unit output\n",
    "}\n",
    "for i in range(7):\n",
    "    losses[f\"numerical_output_{i}\"] = \"sparse_categorical_crossentropy\"  # For numerical outputs\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=losses,  # Same loss for all outputs\n",
    "    metrics=['accuracy']  # Same metric for all outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726329881.498402  238357 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 280s 348ms/step - loss: 9.4453 - numerical_output_0_loss: 2.0852 - numerical_output_1_loss: 2.2060 - numerical_output_2_loss: 1.5662 - numerical_output_3_loss: 1.8353 - numerical_output_4_loss: 0.6234 - numerical_output_5_loss: 0.0535 - numerical_output_6_loss: 0.0251 - units_loss: 1.0509 - numerical_output_0_accuracy: 0.2824 - numerical_output_1_accuracy: 0.2998 - numerical_output_2_accuracy: 0.5744 - numerical_output_3_accuracy: 0.3942 - numerical_output_4_accuracy: 0.8539 - numerical_output_5_accuracy: 0.9946 - numerical_output_6_accuracy: 0.9980 - units_accuracy: 0.4983 - val_loss: 9.1819 - val_numerical_output_0_loss: 2.0264 - val_numerical_output_1_loss: 2.1895 - val_numerical_output_2_loss: 1.4920 - val_numerical_output_3_loss: 1.7960 - val_numerical_output_4_loss: 0.5936 - val_numerical_output_5_loss: 0.0464 - val_numerical_output_6_loss: 0.0093 - val_units_loss: 1.0286 - val_numerical_output_0_accuracy: 0.3033 - val_numerical_output_1_accuracy: 0.2992 - val_numerical_output_2_accuracy: 0.5846 - val_numerical_output_3_accuracy: 0.4067 - val_numerical_output_4_accuracy: 0.8548 - val_numerical_output_5_accuracy: 0.9936 - val_numerical_output_6_accuracy: 0.9991 - val_units_accuracy: 0.5225 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "609/612 [============================>.] - ETA: 0s - loss: 9.1459 - numerical_output_0_loss: 2.0445 - numerical_output_1_loss: 2.1568 - numerical_output_2_loss: 1.5175 - numerical_output_3_loss: 1.7781 - numerical_output_4_loss: 0.5719 - numerical_output_5_loss: 0.0350 - numerical_output_6_loss: 0.0056 - units_loss: 1.0364 - numerical_output_0_accuracy: 0.2901 - numerical_output_1_accuracy: 0.3093 - numerical_output_2_accuracy: 0.5814 - numerical_output_3_accuracy: 0.4028 - numerical_output_4_accuracy: 0.8605 - numerical_output_5_accuracy: 0.9956 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.5089"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blank/miniconda3/envs/tf/lib/python3.10/site-packages/transformers/generation/tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 217s 331ms/step - loss: 9.1474 - numerical_output_0_loss: 2.0444 - numerical_output_1_loss: 2.1573 - numerical_output_2_loss: 1.5174 - numerical_output_3_loss: 1.7782 - numerical_output_4_loss: 0.5730 - numerical_output_5_loss: 0.0349 - numerical_output_6_loss: 0.0056 - units_loss: 1.0366 - numerical_output_0_accuracy: 0.2902 - numerical_output_1_accuracy: 0.3091 - numerical_output_2_accuracy: 0.5814 - numerical_output_3_accuracy: 0.4029 - numerical_output_4_accuracy: 0.8601 - numerical_output_5_accuracy: 0.9956 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.5087 - val_loss: 9.2017 - val_numerical_output_0_loss: 2.0561 - val_numerical_output_1_loss: 2.1382 - val_numerical_output_2_loss: 1.5396 - val_numerical_output_3_loss: 1.7656 - val_numerical_output_4_loss: 0.5933 - val_numerical_output_5_loss: 0.0304 - val_numerical_output_6_loss: 0.0057 - val_units_loss: 1.0728 - val_numerical_output_0_accuracy: 0.2767 - val_numerical_output_1_accuracy: 0.3143 - val_numerical_output_2_accuracy: 0.5708 - val_numerical_output_3_accuracy: 0.3989 - val_numerical_output_4_accuracy: 0.8534 - val_numerical_output_5_accuracy: 0.9963 - val_numerical_output_6_accuracy: 0.9995 - val_units_accuracy: 0.4936 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "612/612 [==============================] - 216s 329ms/step - loss: 9.0874 - numerical_output_0_loss: 2.0397 - numerical_output_1_loss: 2.1382 - numerical_output_2_loss: 1.5023 - numerical_output_3_loss: 1.7601 - numerical_output_4_loss: 0.5730 - numerical_output_5_loss: 0.0344 - numerical_output_6_loss: 0.0054 - units_loss: 1.0344 - numerical_output_0_accuracy: 0.2920 - numerical_output_1_accuracy: 0.3096 - numerical_output_2_accuracy: 0.5796 - numerical_output_3_accuracy: 0.4070 - numerical_output_4_accuracy: 0.8584 - numerical_output_5_accuracy: 0.9956 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.5069 - val_loss: 9.2570 - val_numerical_output_0_loss: 2.0329 - val_numerical_output_1_loss: 2.2343 - val_numerical_output_2_loss: 1.5372 - val_numerical_output_3_loss: 1.7978 - val_numerical_output_4_loss: 0.5912 - val_numerical_output_5_loss: 0.0472 - val_numerical_output_6_loss: 0.0044 - val_units_loss: 1.0120 - val_numerical_output_0_accuracy: 0.2973 - val_numerical_output_1_accuracy: 0.3051 - val_numerical_output_2_accuracy: 0.5777 - val_numerical_output_3_accuracy: 0.3065 - val_numerical_output_4_accuracy: 0.8571 - val_numerical_output_5_accuracy: 0.9949 - val_numerical_output_6_accuracy: 0.9995 - val_units_accuracy: 0.5248 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "612/612 [==============================] - 217s 331ms/step - loss: 9.0383 - numerical_output_0_loss: 2.0363 - numerical_output_1_loss: 2.1307 - numerical_output_2_loss: 1.4885 - numerical_output_3_loss: 1.7447 - numerical_output_4_loss: 0.5639 - numerical_output_5_loss: 0.0331 - numerical_output_6_loss: 0.0046 - units_loss: 1.0364 - numerical_output_0_accuracy: 0.2908 - numerical_output_1_accuracy: 0.3114 - numerical_output_2_accuracy: 0.5809 - numerical_output_3_accuracy: 0.4109 - numerical_output_4_accuracy: 0.8602 - numerical_output_5_accuracy: 0.9957 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.5061 - val_loss: 9.2650 - val_numerical_output_0_loss: 2.0377 - val_numerical_output_1_loss: 2.2113 - val_numerical_output_2_loss: 1.5112 - val_numerical_output_3_loss: 1.8082 - val_numerical_output_4_loss: 0.5924 - val_numerical_output_5_loss: 0.0444 - val_numerical_output_6_loss: 0.0138 - val_units_loss: 1.0460 - val_numerical_output_0_accuracy: 0.2757 - val_numerical_output_1_accuracy: 0.2495 - val_numerical_output_2_accuracy: 0.5781 - val_numerical_output_3_accuracy: 0.4049 - val_numerical_output_4_accuracy: 0.8603 - val_numerical_output_5_accuracy: 0.9945 - val_numerical_output_6_accuracy: 0.9986 - val_units_accuracy: 0.5156 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "612/612 [==============================] - 216s 330ms/step - loss: 8.9661 - numerical_output_0_loss: 2.0312 - numerical_output_1_loss: 2.1056 - numerical_output_2_loss: 1.4792 - numerical_output_3_loss: 1.7300 - numerical_output_4_loss: 0.5547 - numerical_output_5_loss: 0.0330 - numerical_output_6_loss: 0.0045 - units_loss: 1.0277 - numerical_output_0_accuracy: 0.2909 - numerical_output_1_accuracy: 0.3163 - numerical_output_2_accuracy: 0.5806 - numerical_output_3_accuracy: 0.4244 - numerical_output_4_accuracy: 0.8602 - numerical_output_5_accuracy: 0.9956 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.5110 - val_loss: 8.9097 - val_numerical_output_0_loss: 2.0336 - val_numerical_output_1_loss: 2.1003 - val_numerical_output_2_loss: 1.4732 - val_numerical_output_3_loss: 1.6890 - val_numerical_output_4_loss: 0.5310 - val_numerical_output_5_loss: 0.0487 - val_numerical_output_6_loss: 0.0053 - val_units_loss: 1.0286 - val_numerical_output_0_accuracy: 0.2868 - val_numerical_output_1_accuracy: 0.3208 - val_numerical_output_2_accuracy: 0.5804 - val_numerical_output_3_accuracy: 0.4306 - val_numerical_output_4_accuracy: 0.8598 - val_numerical_output_5_accuracy: 0.9931 - val_numerical_output_6_accuracy: 0.9995 - val_units_accuracy: 0.5119 - lr: 2.0000e-04\n",
      "Epoch 6/100\n",
      "612/612 [==============================] - 219s 331ms/step - loss: 8.9300 - numerical_output_0_loss: 2.0303 - numerical_output_1_loss: 2.0891 - numerical_output_2_loss: 1.4796 - numerical_output_3_loss: 1.7164 - numerical_output_4_loss: 0.5509 - numerical_output_5_loss: 0.0319 - numerical_output_6_loss: 0.0039 - units_loss: 1.0280 - numerical_output_0_accuracy: 0.2907 - numerical_output_1_accuracy: 0.3235 - numerical_output_2_accuracy: 0.5783 - numerical_output_3_accuracy: 0.4372 - numerical_output_4_accuracy: 0.8601 - numerical_output_5_accuracy: 0.9957 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.5090 - val_loss: 8.9550 - val_numerical_output_0_loss: 2.0155 - val_numerical_output_1_loss: 2.0783 - val_numerical_output_2_loss: 1.4887 - val_numerical_output_3_loss: 1.7200 - val_numerical_output_4_loss: 0.5870 - val_numerical_output_5_loss: 0.0386 - val_numerical_output_6_loss: 3.0896e-04 - val_units_loss: 1.0265 - val_numerical_output_0_accuracy: 0.2946 - val_numerical_output_1_accuracy: 0.3300 - val_numerical_output_2_accuracy: 0.5699 - val_numerical_output_3_accuracy: 0.4435 - val_numerical_output_4_accuracy: 0.8497 - val_numerical_output_5_accuracy: 0.9945 - val_numerical_output_6_accuracy: 1.0000 - val_units_accuracy: 0.5115 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "612/612 [==============================] - 215s 329ms/step - loss: 8.8930 - numerical_output_0_loss: 2.0279 - numerical_output_1_loss: 2.0848 - numerical_output_2_loss: 1.4646 - numerical_output_3_loss: 1.7099 - numerical_output_4_loss: 0.5470 - numerical_output_5_loss: 0.0306 - numerical_output_6_loss: 0.0029 - units_loss: 1.0253 - numerical_output_0_accuracy: 0.2903 - numerical_output_1_accuracy: 0.3241 - numerical_output_2_accuracy: 0.5824 - numerical_output_3_accuracy: 0.4444 - numerical_output_4_accuracy: 0.8613 - numerical_output_5_accuracy: 0.9958 - numerical_output_6_accuracy: 0.9997 - units_accuracy: 0.5115 - val_loss: 8.7940 - val_numerical_output_0_loss: 2.0209 - val_numerical_output_1_loss: 2.0907 - val_numerical_output_2_loss: 1.4035 - val_numerical_output_3_loss: 1.6778 - val_numerical_output_4_loss: 0.5462 - val_numerical_output_5_loss: 0.0330 - val_numerical_output_6_loss: 0.0054 - val_units_loss: 1.0166 - val_numerical_output_0_accuracy: 0.2950 - val_numerical_output_1_accuracy: 0.3180 - val_numerical_output_2_accuracy: 0.5983 - val_numerical_output_3_accuracy: 0.4481 - val_numerical_output_4_accuracy: 0.8635 - val_numerical_output_5_accuracy: 0.9954 - val_numerical_output_6_accuracy: 0.9995 - val_units_accuracy: 0.5253 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "612/612 [==============================] - 232s 355ms/step - loss: 8.8376 - numerical_output_0_loss: 2.0283 - numerical_output_1_loss: 2.0626 - numerical_output_2_loss: 1.4573 - numerical_output_3_loss: 1.6956 - numerical_output_4_loss: 0.5471 - numerical_output_5_loss: 0.0303 - numerical_output_6_loss: 0.0039 - units_loss: 1.0125 - numerical_output_0_accuracy: 0.2897 - numerical_output_1_accuracy: 0.3314 - numerical_output_2_accuracy: 0.5798 - numerical_output_3_accuracy: 0.4562 - numerical_output_4_accuracy: 0.8612 - numerical_output_5_accuracy: 0.9959 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.5218 - val_loss: 8.8236 - val_numerical_output_0_loss: 2.0002 - val_numerical_output_1_loss: 2.0684 - val_numerical_output_2_loss: 1.4435 - val_numerical_output_3_loss: 1.6790 - val_numerical_output_4_loss: 0.5826 - val_numerical_output_5_loss: 0.0352 - val_numerical_output_6_loss: 0.0092 - val_units_loss: 1.0054 - val_numerical_output_0_accuracy: 0.3001 - val_numerical_output_1_accuracy: 0.3208 - val_numerical_output_2_accuracy: 0.5790 - val_numerical_output_3_accuracy: 0.4651 - val_numerical_output_4_accuracy: 0.8529 - val_numerical_output_5_accuracy: 0.9954 - val_numerical_output_6_accuracy: 0.9991 - val_units_accuracy: 0.5345 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "612/612 [==============================] - 216s 329ms/step - loss: 8.7808 - numerical_output_0_loss: 2.0261 - numerical_output_1_loss: 2.0519 - numerical_output_2_loss: 1.4493 - numerical_output_3_loss: 1.6815 - numerical_output_4_loss: 0.5438 - numerical_output_5_loss: 0.0318 - numerical_output_6_loss: 0.0049 - units_loss: 0.9914 - numerical_output_0_accuracy: 0.2898 - numerical_output_1_accuracy: 0.3352 - numerical_output_2_accuracy: 0.5807 - numerical_output_3_accuracy: 0.4670 - numerical_output_4_accuracy: 0.8608 - numerical_output_5_accuracy: 0.9958 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.5455 - val_loss: 8.6251 - val_numerical_output_0_loss: 2.0301 - val_numerical_output_1_loss: 2.0352 - val_numerical_output_2_loss: 1.4003 - val_numerical_output_3_loss: 1.6213 - val_numerical_output_4_loss: 0.4841 - val_numerical_output_5_loss: 0.0413 - val_numerical_output_6_loss: 0.0143 - val_units_loss: 0.9985 - val_numerical_output_0_accuracy: 0.2812 - val_numerical_output_1_accuracy: 0.3346 - val_numerical_output_2_accuracy: 0.5919 - val_numerical_output_3_accuracy: 0.5000 - val_numerical_output_4_accuracy: 0.8755 - val_numerical_output_5_accuracy: 0.9945 - val_numerical_output_6_accuracy: 0.9986 - val_units_accuracy: 0.5409 - lr: 2.0000e-04\n",
      "Epoch 10/100\n",
      "612/612 [==============================] - 217s 331ms/step - loss: 8.7063 - numerical_output_0_loss: 2.0182 - numerical_output_1_loss: 2.0338 - numerical_output_2_loss: 1.4352 - numerical_output_3_loss: 1.6621 - numerical_output_4_loss: 0.5418 - numerical_output_5_loss: 0.0304 - numerical_output_6_loss: 0.0043 - units_loss: 0.9805 - numerical_output_0_accuracy: 0.2905 - numerical_output_1_accuracy: 0.3403 - numerical_output_2_accuracy: 0.5804 - numerical_output_3_accuracy: 0.4725 - numerical_output_4_accuracy: 0.8602 - numerical_output_5_accuracy: 0.9958 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.5627 - val_loss: 8.6401 - val_numerical_output_0_loss: 2.0224 - val_numerical_output_1_loss: 1.9788 - val_numerical_output_2_loss: 1.4344 - val_numerical_output_3_loss: 1.6535 - val_numerical_output_4_loss: 0.5173 - val_numerical_output_5_loss: 0.0296 - val_numerical_output_6_loss: 0.0093 - val_units_loss: 0.9947 - val_numerical_output_0_accuracy: 0.2831 - val_numerical_output_1_accuracy: 0.3603 - val_numerical_output_2_accuracy: 0.5712 - val_numerical_output_3_accuracy: 0.4839 - val_numerical_output_4_accuracy: 0.8631 - val_numerical_output_5_accuracy: 0.9968 - val_numerical_output_6_accuracy: 0.9991 - val_units_accuracy: 0.5418 - lr: 2.0000e-04\n",
      "Epoch 11/100\n",
      "612/612 [==============================] - 216s 329ms/step - loss: 8.5450 - numerical_output_0_loss: 2.0125 - numerical_output_1_loss: 1.9893 - numerical_output_2_loss: 1.4075 - numerical_output_3_loss: 1.6207 - numerical_output_4_loss: 0.5284 - numerical_output_5_loss: 0.0295 - numerical_output_6_loss: 0.0049 - units_loss: 0.9521 - numerical_output_0_accuracy: 0.2917 - numerical_output_1_accuracy: 0.3522 - numerical_output_2_accuracy: 0.5816 - numerical_output_3_accuracy: 0.4996 - numerical_output_4_accuracy: 0.8609 - numerical_output_5_accuracy: 0.9959 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.5779 - val_loss: 8.4069 - val_numerical_output_0_loss: 1.9966 - val_numerical_output_1_loss: 1.9594 - val_numerical_output_2_loss: 1.3703 - val_numerical_output_3_loss: 1.5865 - val_numerical_output_4_loss: 0.5131 - val_numerical_output_5_loss: 0.0358 - val_numerical_output_6_loss: 0.0044 - val_units_loss: 0.9407 - val_numerical_output_0_accuracy: 0.2960 - val_numerical_output_1_accuracy: 0.3649 - val_numerical_output_2_accuracy: 0.5855 - val_numerical_output_3_accuracy: 0.5175 - val_numerical_output_4_accuracy: 0.8603 - val_numerical_output_5_accuracy: 0.9949 - val_numerical_output_6_accuracy: 0.9995 - val_units_accuracy: 0.5882 - lr: 2.0000e-05\n",
      "Epoch 12/100\n",
      "612/612 [==============================] - 218s 331ms/step - loss: 8.4743 - numerical_output_0_loss: 2.0072 - numerical_output_1_loss: 1.9680 - numerical_output_2_loss: 1.3942 - numerical_output_3_loss: 1.6055 - numerical_output_4_loss: 0.5248 - numerical_output_5_loss: 0.0288 - numerical_output_6_loss: 0.0044 - units_loss: 0.9415 - numerical_output_0_accuracy: 0.2906 - numerical_output_1_accuracy: 0.3573 - numerical_output_2_accuracy: 0.5829 - numerical_output_3_accuracy: 0.5085 - numerical_output_4_accuracy: 0.8605 - numerical_output_5_accuracy: 0.9960 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.5879 - val_loss: 8.3417 - val_numerical_output_0_loss: 1.9842 - val_numerical_output_1_loss: 1.9487 - val_numerical_output_2_loss: 1.3735 - val_numerical_output_3_loss: 1.5498 - val_numerical_output_4_loss: 0.5409 - val_numerical_output_5_loss: 0.0222 - val_numerical_output_6_loss: 4.3512e-04 - val_units_loss: 0.9220 - val_numerical_output_0_accuracy: 0.3024 - val_numerical_output_1_accuracy: 0.3681 - val_numerical_output_2_accuracy: 0.5846 - val_numerical_output_3_accuracy: 0.5363 - val_numerical_output_4_accuracy: 0.8552 - val_numerical_output_5_accuracy: 0.9968 - val_numerical_output_6_accuracy: 1.0000 - val_units_accuracy: 0.6043 - lr: 2.0000e-05\n",
      "Epoch 13/100\n",
      "612/612 [==============================] - 215s 328ms/step - loss: 8.4459 - numerical_output_0_loss: 2.0023 - numerical_output_1_loss: 1.9607 - numerical_output_2_loss: 1.3872 - numerical_output_3_loss: 1.5983 - numerical_output_4_loss: 0.5250 - numerical_output_5_loss: 0.0300 - numerical_output_6_loss: 0.0049 - units_loss: 0.9376 - numerical_output_0_accuracy: 0.2933 - numerical_output_1_accuracy: 0.3599 - numerical_output_2_accuracy: 0.5844 - numerical_output_3_accuracy: 0.5148 - numerical_output_4_accuracy: 0.8602 - numerical_output_5_accuracy: 0.9958 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.5885 - val_loss: 8.3420 - val_numerical_output_0_loss: 1.9943 - val_numerical_output_1_loss: 1.9110 - val_numerical_output_2_loss: 1.3615 - val_numerical_output_3_loss: 1.5829 - val_numerical_output_4_loss: 0.5308 - val_numerical_output_5_loss: 0.0217 - val_numerical_output_6_loss: 0.0053 - val_units_loss: 0.9346 - val_numerical_output_0_accuracy: 0.2960 - val_numerical_output_1_accuracy: 0.3860 - val_numerical_output_2_accuracy: 0.5763 - val_numerical_output_3_accuracy: 0.5308 - val_numerical_output_4_accuracy: 0.8543 - val_numerical_output_5_accuracy: 0.9972 - val_numerical_output_6_accuracy: 0.9995 - val_units_accuracy: 0.5781 - lr: 2.0000e-05\n",
      "Epoch 14/100\n",
      "612/612 [==============================] - 218s 331ms/step - loss: 8.3813 - numerical_output_0_loss: 2.0002 - numerical_output_1_loss: 1.9429 - numerical_output_2_loss: 1.3728 - numerical_output_3_loss: 1.5811 - numerical_output_4_loss: 0.5206 - numerical_output_5_loss: 0.0295 - numerical_output_6_loss: 0.0044 - units_loss: 0.9298 - numerical_output_0_accuracy: 0.2926 - numerical_output_1_accuracy: 0.3667 - numerical_output_2_accuracy: 0.5857 - numerical_output_3_accuracy: 0.5225 - numerical_output_4_accuracy: 0.8604 - numerical_output_5_accuracy: 0.9959 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.5952 - val_loss: 8.2168 - val_numerical_output_0_loss: 1.9810 - val_numerical_output_1_loss: 1.8814 - val_numerical_output_2_loss: 1.3550 - val_numerical_output_3_loss: 1.5381 - val_numerical_output_4_loss: 0.5130 - val_numerical_output_5_loss: 0.0411 - val_numerical_output_6_loss: 0.0166 - val_units_loss: 0.8908 - val_numerical_output_0_accuracy: 0.2904 - val_numerical_output_1_accuracy: 0.3819 - val_numerical_output_2_accuracy: 0.5873 - val_numerical_output_3_accuracy: 0.5487 - val_numerical_output_4_accuracy: 0.8617 - val_numerical_output_5_accuracy: 0.9940 - val_numerical_output_6_accuracy: 0.9982 - val_units_accuracy: 0.6140 - lr: 2.0000e-05\n",
      "Epoch 15/100\n",
      "612/612 [==============================] - 218s 329ms/step - loss: 8.3248 - numerical_output_0_loss: 1.9966 - numerical_output_1_loss: 1.9316 - numerical_output_2_loss: 1.3604 - numerical_output_3_loss: 1.5628 - numerical_output_4_loss: 0.5166 - numerical_output_5_loss: 0.0300 - numerical_output_6_loss: 0.0045 - units_loss: 0.9225 - numerical_output_0_accuracy: 0.2943 - numerical_output_1_accuracy: 0.3706 - numerical_output_2_accuracy: 0.5924 - numerical_output_3_accuracy: 0.5332 - numerical_output_4_accuracy: 0.8608 - numerical_output_5_accuracy: 0.9958 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.5948 - val_loss: 8.1186 - val_numerical_output_0_loss: 1.9918 - val_numerical_output_1_loss: 1.8855 - val_numerical_output_2_loss: 1.3209 - val_numerical_output_3_loss: 1.5002 - val_numerical_output_4_loss: 0.4900 - val_numerical_output_5_loss: 0.0372 - val_numerical_output_6_loss: 0.0042 - val_units_loss: 0.8888 - val_numerical_output_0_accuracy: 0.2946 - val_numerical_output_1_accuracy: 0.3741 - val_numerical_output_2_accuracy: 0.6117 - val_numerical_output_3_accuracy: 0.5593 - val_numerical_output_4_accuracy: 0.8663 - val_numerical_output_5_accuracy: 0.9945 - val_numerical_output_6_accuracy: 0.9995 - val_units_accuracy: 0.6066 - lr: 2.0000e-05\n",
      "Epoch 16/100\n",
      "612/612 [==============================] - 217s 330ms/step - loss: 8.2586 - numerical_output_0_loss: 1.9899 - numerical_output_1_loss: 1.9103 - numerical_output_2_loss: 1.3526 - numerical_output_3_loss: 1.5448 - numerical_output_4_loss: 0.5133 - numerical_output_5_loss: 0.0317 - numerical_output_6_loss: 0.0046 - units_loss: 0.9115 - numerical_output_0_accuracy: 0.2962 - numerical_output_1_accuracy: 0.3751 - numerical_output_2_accuracy: 0.5933 - numerical_output_3_accuracy: 0.5412 - numerical_output_4_accuracy: 0.8617 - numerical_output_5_accuracy: 0.9955 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.6004 - val_loss: 8.0550 - val_numerical_output_0_loss: 1.9717 - val_numerical_output_1_loss: 1.8816 - val_numerical_output_2_loss: 1.3134 - val_numerical_output_3_loss: 1.4880 - val_numerical_output_4_loss: 0.4698 - val_numerical_output_5_loss: 0.0272 - val_numerical_output_6_loss: 4.8538e-04 - val_units_loss: 0.9028 - val_numerical_output_0_accuracy: 0.3042 - val_numerical_output_1_accuracy: 0.3865 - val_numerical_output_2_accuracy: 0.6029 - val_numerical_output_3_accuracy: 0.5676 - val_numerical_output_4_accuracy: 0.8644 - val_numerical_output_5_accuracy: 0.9949 - val_numerical_output_6_accuracy: 1.0000 - val_units_accuracy: 0.6094 - lr: 2.0000e-05\n",
      "Epoch 17/100\n",
      "612/612 [==============================] - 215s 328ms/step - loss: 8.1886 - numerical_output_0_loss: 1.9876 - numerical_output_1_loss: 1.8904 - numerical_output_2_loss: 1.3340 - numerical_output_3_loss: 1.5303 - numerical_output_4_loss: 0.5095 - numerical_output_5_loss: 0.0293 - numerical_output_6_loss: 0.0047 - units_loss: 0.9027 - numerical_output_0_accuracy: 0.2959 - numerical_output_1_accuracy: 0.3829 - numerical_output_2_accuracy: 0.5970 - numerical_output_3_accuracy: 0.5532 - numerical_output_4_accuracy: 0.8617 - numerical_output_5_accuracy: 0.9958 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.6060 - val_loss: 8.0287 - val_numerical_output_0_loss: 1.9915 - val_numerical_output_1_loss: 1.8396 - val_numerical_output_2_loss: 1.3153 - val_numerical_output_3_loss: 1.4563 - val_numerical_output_4_loss: 0.5074 - val_numerical_output_5_loss: 0.0328 - val_numerical_output_6_loss: 0.0091 - val_units_loss: 0.8768 - val_numerical_output_0_accuracy: 0.2891 - val_numerical_output_1_accuracy: 0.4007 - val_numerical_output_2_accuracy: 0.5882 - val_numerical_output_3_accuracy: 0.5699 - val_numerical_output_4_accuracy: 0.8543 - val_numerical_output_5_accuracy: 0.9954 - val_numerical_output_6_accuracy: 0.9991 - val_units_accuracy: 0.6351 - lr: 2.0000e-05\n",
      "Epoch 18/100\n",
      "612/612 [==============================] - 218s 333ms/step - loss: 8.1207 - numerical_output_0_loss: 1.9821 - numerical_output_1_loss: 1.8656 - numerical_output_2_loss: 1.3212 - numerical_output_3_loss: 1.5082 - numerical_output_4_loss: 0.5112 - numerical_output_5_loss: 0.0304 - numerical_output_6_loss: 0.0044 - units_loss: 0.8977 - numerical_output_0_accuracy: 0.2941 - numerical_output_1_accuracy: 0.3877 - numerical_output_2_accuracy: 0.6011 - numerical_output_3_accuracy: 0.5621 - numerical_output_4_accuracy: 0.8597 - numerical_output_5_accuracy: 0.9957 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.6083 - val_loss: 7.8324 - val_numerical_output_0_loss: 1.9765 - val_numerical_output_1_loss: 1.8060 - val_numerical_output_2_loss: 1.2963 - val_numerical_output_3_loss: 1.4026 - val_numerical_output_4_loss: 0.4683 - val_numerical_output_5_loss: 0.0260 - val_numerical_output_6_loss: 5.0665e-04 - val_units_loss: 0.8562 - val_numerical_output_0_accuracy: 0.3001 - val_numerical_output_1_accuracy: 0.3989 - val_numerical_output_2_accuracy: 0.6250 - val_numerical_output_3_accuracy: 0.6121 - val_numerical_output_4_accuracy: 0.8704 - val_numerical_output_5_accuracy: 0.9954 - val_numerical_output_6_accuracy: 1.0000 - val_units_accuracy: 0.6314 - lr: 2.0000e-05\n",
      "Epoch 19/100\n",
      "612/612 [==============================] - 216s 328ms/step - loss: 8.0404 - numerical_output_0_loss: 1.9768 - numerical_output_1_loss: 1.8489 - numerical_output_2_loss: 1.2988 - numerical_output_3_loss: 1.4883 - numerical_output_4_loss: 0.5060 - numerical_output_5_loss: 0.0300 - numerical_output_6_loss: 0.0050 - units_loss: 0.8867 - numerical_output_0_accuracy: 0.2977 - numerical_output_1_accuracy: 0.3911 - numerical_output_2_accuracy: 0.6140 - numerical_output_3_accuracy: 0.5699 - numerical_output_4_accuracy: 0.8607 - numerical_output_5_accuracy: 0.9958 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.6131 - val_loss: 7.7221 - val_numerical_output_0_loss: 1.9539 - val_numerical_output_1_loss: 1.8010 - val_numerical_output_2_loss: 1.2365 - val_numerical_output_3_loss: 1.4018 - val_numerical_output_4_loss: 0.4623 - val_numerical_output_5_loss: 0.0279 - val_numerical_output_6_loss: 0.0090 - val_units_loss: 0.8297 - val_numerical_output_0_accuracy: 0.3056 - val_numerical_output_1_accuracy: 0.4003 - val_numerical_output_2_accuracy: 0.6255 - val_numerical_output_3_accuracy: 0.6002 - val_numerical_output_4_accuracy: 0.8663 - val_numerical_output_5_accuracy: 0.9959 - val_numerical_output_6_accuracy: 0.9991 - val_units_accuracy: 0.6388 - lr: 2.0000e-05\n",
      "Epoch 20/100\n",
      "612/612 [==============================] - 217s 331ms/step - loss: 7.9380 - numerical_output_0_loss: 1.9708 - numerical_output_1_loss: 1.8148 - numerical_output_2_loss: 1.2801 - numerical_output_3_loss: 1.4572 - numerical_output_4_loss: 0.5047 - numerical_output_5_loss: 0.0290 - numerical_output_6_loss: 0.0036 - units_loss: 0.8778 - numerical_output_0_accuracy: 0.2998 - numerical_output_1_accuracy: 0.4005 - numerical_output_2_accuracy: 0.6199 - numerical_output_3_accuracy: 0.5823 - numerical_output_4_accuracy: 0.8587 - numerical_output_5_accuracy: 0.9957 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.6172 - val_loss: 7.7060 - val_numerical_output_0_loss: 1.9406 - val_numerical_output_1_loss: 1.7484 - val_numerical_output_2_loss: 1.2458 - val_numerical_output_3_loss: 1.3904 - val_numerical_output_4_loss: 0.5033 - val_numerical_output_5_loss: 0.0355 - val_numerical_output_6_loss: 0.0041 - val_units_loss: 0.8380 - val_numerical_output_0_accuracy: 0.3042 - val_numerical_output_1_accuracy: 0.4076 - val_numerical_output_2_accuracy: 0.6411 - val_numerical_output_3_accuracy: 0.6052 - val_numerical_output_4_accuracy: 0.8488 - val_numerical_output_5_accuracy: 0.9949 - val_numerical_output_6_accuracy: 0.9995 - val_units_accuracy: 0.6273 - lr: 2.0000e-05\n",
      "Epoch 21/100\n",
      "612/612 [==============================] - 216s 328ms/step - loss: 7.7820 - numerical_output_0_loss: 1.9609 - numerical_output_1_loss: 1.7723 - numerical_output_2_loss: 1.2509 - numerical_output_3_loss: 1.4128 - numerical_output_4_loss: 0.4898 - numerical_output_5_loss: 0.0288 - numerical_output_6_loss: 0.0041 - units_loss: 0.8623 - numerical_output_0_accuracy: 0.2995 - numerical_output_1_accuracy: 0.4104 - numerical_output_2_accuracy: 0.6315 - numerical_output_3_accuracy: 0.5972 - numerical_output_4_accuracy: 0.8597 - numerical_output_5_accuracy: 0.9958 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.6263 - val_loss: 7.6755 - val_numerical_output_0_loss: 1.9573 - val_numerical_output_1_loss: 1.7450 - val_numerical_output_2_loss: 1.2041 - val_numerical_output_3_loss: 1.3865 - val_numerical_output_4_loss: 0.4961 - val_numerical_output_5_loss: 0.0406 - val_numerical_output_6_loss: 0.0049 - val_units_loss: 0.8411 - val_numerical_output_0_accuracy: 0.3006 - val_numerical_output_1_accuracy: 0.4131 - val_numerical_output_2_accuracy: 0.6466 - val_numerical_output_3_accuracy: 0.6052 - val_numerical_output_4_accuracy: 0.8571 - val_numerical_output_5_accuracy: 0.9940 - val_numerical_output_6_accuracy: 0.9995 - val_units_accuracy: 0.6255 - lr: 2.0000e-06\n",
      "Epoch 22/100\n",
      "612/612 [==============================] - 217s 330ms/step - loss: 7.7365 - numerical_output_0_loss: 1.9567 - numerical_output_1_loss: 1.7560 - numerical_output_2_loss: 1.2412 - numerical_output_3_loss: 1.4029 - numerical_output_4_loss: 0.4900 - numerical_output_5_loss: 0.0294 - numerical_output_6_loss: 0.0044 - units_loss: 0.8558 - numerical_output_0_accuracy: 0.3010 - numerical_output_1_accuracy: 0.4160 - numerical_output_2_accuracy: 0.6348 - numerical_output_3_accuracy: 0.6033 - numerical_output_4_accuracy: 0.8606 - numerical_output_5_accuracy: 0.9958 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.6258 - val_loss: 7.6791 - val_numerical_output_0_loss: 1.9168 - val_numerical_output_1_loss: 1.7524 - val_numerical_output_2_loss: 1.2152 - val_numerical_output_3_loss: 1.4088 - val_numerical_output_4_loss: 0.5128 - val_numerical_output_5_loss: 0.0435 - val_numerical_output_6_loss: 0.0084 - val_units_loss: 0.8212 - val_numerical_output_0_accuracy: 0.3148 - val_numerical_output_1_accuracy: 0.4095 - val_numerical_output_2_accuracy: 0.6448 - val_numerical_output_3_accuracy: 0.5905 - val_numerical_output_4_accuracy: 0.8465 - val_numerical_output_5_accuracy: 0.9936 - val_numerical_output_6_accuracy: 0.9991 - val_units_accuracy: 0.6461 - lr: 2.0000e-06\n",
      "Epoch 23/100\n",
      "612/612 [==============================] - 215s 328ms/step - loss: 7.7293 - numerical_output_0_loss: 1.9561 - numerical_output_1_loss: 1.7574 - numerical_output_2_loss: 1.2334 - numerical_output_3_loss: 1.4010 - numerical_output_4_loss: 0.4932 - numerical_output_5_loss: 0.0293 - numerical_output_6_loss: 0.0042 - units_loss: 0.8546 - numerical_output_0_accuracy: 0.3015 - numerical_output_1_accuracy: 0.4139 - numerical_output_2_accuracy: 0.6382 - numerical_output_3_accuracy: 0.6038 - numerical_output_4_accuracy: 0.8605 - numerical_output_5_accuracy: 0.9957 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.6257 - val_loss: 7.4576 - val_numerical_output_0_loss: 1.9320 - val_numerical_output_1_loss: 1.6648 - val_numerical_output_2_loss: 1.1865 - val_numerical_output_3_loss: 1.3208 - val_numerical_output_4_loss: 0.4708 - val_numerical_output_5_loss: 0.0333 - val_numerical_output_6_loss: 0.0086 - val_units_loss: 0.8409 - val_numerical_output_0_accuracy: 0.3244 - val_numerical_output_1_accuracy: 0.4347 - val_numerical_output_2_accuracy: 0.6544 - val_numerical_output_3_accuracy: 0.6232 - val_numerical_output_4_accuracy: 0.8594 - val_numerical_output_5_accuracy: 0.9949 - val_numerical_output_6_accuracy: 0.9991 - val_units_accuracy: 0.6094 - lr: 2.0000e-06\n",
      "Epoch 24/100\n",
      "612/612 [==============================] - 218s 331ms/step - loss: 7.7046 - numerical_output_0_loss: 1.9610 - numerical_output_1_loss: 1.7420 - numerical_output_2_loss: 1.2292 - numerical_output_3_loss: 1.3972 - numerical_output_4_loss: 0.4901 - numerical_output_5_loss: 0.0298 - numerical_output_6_loss: 0.0037 - units_loss: 0.8515 - numerical_output_0_accuracy: 0.2997 - numerical_output_1_accuracy: 0.4161 - numerical_output_2_accuracy: 0.6412 - numerical_output_3_accuracy: 0.6049 - numerical_output_4_accuracy: 0.8601 - numerical_output_5_accuracy: 0.9958 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.6304 - val_loss: 7.4865 - val_numerical_output_0_loss: 1.9462 - val_numerical_output_1_loss: 1.7329 - val_numerical_output_2_loss: 1.1578 - val_numerical_output_3_loss: 1.3388 - val_numerical_output_4_loss: 0.4581 - val_numerical_output_5_loss: 0.0208 - val_numerical_output_6_loss: 3.9296e-04 - val_units_loss: 0.8315 - val_numerical_output_0_accuracy: 0.3065 - val_numerical_output_1_accuracy: 0.4150 - val_numerical_output_2_accuracy: 0.6654 - val_numerical_output_3_accuracy: 0.6186 - val_numerical_output_4_accuracy: 0.8653 - val_numerical_output_5_accuracy: 0.9968 - val_numerical_output_6_accuracy: 1.0000 - val_units_accuracy: 0.6324 - lr: 2.0000e-06\n",
      "Epoch 25/100\n",
      "612/612 [==============================] - 216s 328ms/step - loss: 7.6695 - numerical_output_0_loss: 1.9536 - numerical_output_1_loss: 1.7416 - numerical_output_2_loss: 1.2181 - numerical_output_3_loss: 1.3835 - numerical_output_4_loss: 0.4864 - numerical_output_5_loss: 0.0299 - numerical_output_6_loss: 0.0043 - units_loss: 0.8522 - numerical_output_0_accuracy: 0.3032 - numerical_output_1_accuracy: 0.4186 - numerical_output_2_accuracy: 0.6437 - numerical_output_3_accuracy: 0.6103 - numerical_output_4_accuracy: 0.8607 - numerical_output_5_accuracy: 0.9957 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.6288 - val_loss: 7.4939 - val_numerical_output_0_loss: 1.9516 - val_numerical_output_1_loss: 1.6786 - val_numerical_output_2_loss: 1.1882 - val_numerical_output_3_loss: 1.3391 - val_numerical_output_4_loss: 0.5044 - val_numerical_output_5_loss: 0.0229 - val_numerical_output_6_loss: 3.9439e-04 - val_units_loss: 0.8086 - val_numerical_output_0_accuracy: 0.3162 - val_numerical_output_1_accuracy: 0.4278 - val_numerical_output_2_accuracy: 0.6558 - val_numerical_output_3_accuracy: 0.6153 - val_numerical_output_4_accuracy: 0.8497 - val_numerical_output_5_accuracy: 0.9968 - val_numerical_output_6_accuracy: 1.0000 - val_units_accuracy: 0.6402 - lr: 2.0000e-06\n",
      "Epoch 26/100\n",
      "612/612 [==============================] - 217s 330ms/step - loss: 7.6605 - numerical_output_0_loss: 1.9522 - numerical_output_1_loss: 1.7358 - numerical_output_2_loss: 1.2121 - numerical_output_3_loss: 1.3858 - numerical_output_4_loss: 0.4921 - numerical_output_5_loss: 0.0291 - numerical_output_6_loss: 0.0045 - units_loss: 0.8489 - numerical_output_0_accuracy: 0.3050 - numerical_output_1_accuracy: 0.4155 - numerical_output_2_accuracy: 0.6447 - numerical_output_3_accuracy: 0.6085 - numerical_output_4_accuracy: 0.8594 - numerical_output_5_accuracy: 0.9957 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.6310 - val_loss: 7.5514 - val_numerical_output_0_loss: 1.9276 - val_numerical_output_1_loss: 1.7045 - val_numerical_output_2_loss: 1.1713 - val_numerical_output_3_loss: 1.3443 - val_numerical_output_4_loss: 0.5257 - val_numerical_output_5_loss: 0.0337 - val_numerical_output_6_loss: 0.0048 - val_units_loss: 0.8393 - val_numerical_output_0_accuracy: 0.3111 - val_numerical_output_1_accuracy: 0.4196 - val_numerical_output_2_accuracy: 0.6627 - val_numerical_output_3_accuracy: 0.6062 - val_numerical_output_4_accuracy: 0.8396 - val_numerical_output_5_accuracy: 0.9945 - val_numerical_output_6_accuracy: 0.9995 - val_units_accuracy: 0.6337 - lr: 2.0000e-06\n",
      "Epoch 27/100\n",
      "612/612 [==============================] - 216s 328ms/step - loss: 7.6277 - numerical_output_0_loss: 1.9528 - numerical_output_1_loss: 1.7317 - numerical_output_2_loss: 1.2040 - numerical_output_3_loss: 1.3747 - numerical_output_4_loss: 0.4865 - numerical_output_5_loss: 0.0281 - numerical_output_6_loss: 0.0044 - units_loss: 0.8456 - numerical_output_0_accuracy: 0.3052 - numerical_output_1_accuracy: 0.4176 - numerical_output_2_accuracy: 0.6499 - numerical_output_3_accuracy: 0.6132 - numerical_output_4_accuracy: 0.8606 - numerical_output_5_accuracy: 0.9958 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.6319 - val_loss: 7.5000 - val_numerical_output_0_loss: 1.9307 - val_numerical_output_1_loss: 1.6837 - val_numerical_output_2_loss: 1.1974 - val_numerical_output_3_loss: 1.3927 - val_numerical_output_4_loss: 0.4610 - val_numerical_output_5_loss: 0.0141 - val_numerical_output_6_loss: 3.8322e-04 - val_units_loss: 0.8200 - val_numerical_output_0_accuracy: 0.3074 - val_numerical_output_1_accuracy: 0.4384 - val_numerical_output_2_accuracy: 0.6553 - val_numerical_output_3_accuracy: 0.6034 - val_numerical_output_4_accuracy: 0.8612 - val_numerical_output_5_accuracy: 0.9977 - val_numerical_output_6_accuracy: 1.0000 - val_units_accuracy: 0.6392 - lr: 2.0000e-06\n",
      "Epoch 28/100\n",
      "612/612 [==============================] - 217s 330ms/step - loss: 7.6123 - numerical_output_0_loss: 1.9511 - numerical_output_1_loss: 1.7175 - numerical_output_2_loss: 1.2085 - numerical_output_3_loss: 1.3696 - numerical_output_4_loss: 0.4844 - numerical_output_5_loss: 0.0295 - numerical_output_6_loss: 0.0047 - units_loss: 0.8472 - numerical_output_0_accuracy: 0.3023 - numerical_output_1_accuracy: 0.4211 - numerical_output_2_accuracy: 0.6470 - numerical_output_3_accuracy: 0.6123 - numerical_output_4_accuracy: 0.8591 - numerical_output_5_accuracy: 0.9958 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.6300 - val_loss: 7.4019 - val_numerical_output_0_loss: 1.9261 - val_numerical_output_1_loss: 1.6265 - val_numerical_output_2_loss: 1.1715 - val_numerical_output_3_loss: 1.2994 - val_numerical_output_4_loss: 0.5070 - val_numerical_output_5_loss: 0.0288 - val_numerical_output_6_loss: 0.0035 - val_units_loss: 0.8389 - val_numerical_output_0_accuracy: 0.3130 - val_numerical_output_1_accuracy: 0.4403 - val_numerical_output_2_accuracy: 0.6526 - val_numerical_output_3_accuracy: 0.6245 - val_numerical_output_4_accuracy: 0.8483 - val_numerical_output_5_accuracy: 0.9959 - val_numerical_output_6_accuracy: 0.9995 - val_units_accuracy: 0.6209 - lr: 2.0000e-06\n",
      "Epoch 29/100\n",
      "612/612 [==============================] - 216s 328ms/step - loss: 7.5947 - numerical_output_0_loss: 1.9490 - numerical_output_1_loss: 1.7176 - numerical_output_2_loss: 1.2022 - numerical_output_3_loss: 1.3596 - numerical_output_4_loss: 0.4862 - numerical_output_5_loss: 0.0305 - numerical_output_6_loss: 0.0046 - units_loss: 0.8451 - numerical_output_0_accuracy: 0.3040 - numerical_output_1_accuracy: 0.4221 - numerical_output_2_accuracy: 0.6499 - numerical_output_3_accuracy: 0.6156 - numerical_output_4_accuracy: 0.8596 - numerical_output_5_accuracy: 0.9956 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.6311 - val_loss: 7.3552 - val_numerical_output_0_loss: 1.9464 - val_numerical_output_1_loss: 1.6255 - val_numerical_output_2_loss: 1.1763 - val_numerical_output_3_loss: 1.2909 - val_numerical_output_4_loss: 0.4733 - val_numerical_output_5_loss: 0.0376 - val_numerical_output_6_loss: 0.0084 - val_units_loss: 0.7968 - val_numerical_output_0_accuracy: 0.2960 - val_numerical_output_1_accuracy: 0.4389 - val_numerical_output_2_accuracy: 0.6443 - val_numerical_output_3_accuracy: 0.6287 - val_numerical_output_4_accuracy: 0.8562 - val_numerical_output_5_accuracy: 0.9945 - val_numerical_output_6_accuracy: 0.9991 - val_units_accuracy: 0.6471 - lr: 2.0000e-06\n",
      "Epoch 30/100\n",
      "612/612 [==============================] - 217s 330ms/step - loss: 7.5749 - numerical_output_0_loss: 1.9492 - numerical_output_1_loss: 1.7085 - numerical_output_2_loss: 1.1977 - numerical_output_3_loss: 1.3611 - numerical_output_4_loss: 0.4796 - numerical_output_5_loss: 0.0292 - numerical_output_6_loss: 0.0036 - units_loss: 0.8458 - numerical_output_0_accuracy: 0.3020 - numerical_output_1_accuracy: 0.4247 - numerical_output_2_accuracy: 0.6494 - numerical_output_3_accuracy: 0.6152 - numerical_output_4_accuracy: 0.8605 - numerical_output_5_accuracy: 0.9956 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.6306 - val_loss: 7.4295 - val_numerical_output_0_loss: 1.9726 - val_numerical_output_1_loss: 1.6587 - val_numerical_output_2_loss: 1.1864 - val_numerical_output_3_loss: 1.2762 - val_numerical_output_4_loss: 0.4696 - val_numerical_output_5_loss: 0.0324 - val_numerical_output_6_loss: 0.0050 - val_units_loss: 0.8285 - val_numerical_output_0_accuracy: 0.2900 - val_numerical_output_1_accuracy: 0.4439 - val_numerical_output_2_accuracy: 0.6590 - val_numerical_output_3_accuracy: 0.6388 - val_numerical_output_4_accuracy: 0.8571 - val_numerical_output_5_accuracy: 0.9949 - val_numerical_output_6_accuracy: 0.9995 - val_units_accuracy: 0.6245 - lr: 2.0000e-06\n",
      "Epoch 31/100\n",
      "612/612 [==============================] - 215s 328ms/step - loss: 7.5474 - numerical_output_0_loss: 1.9485 - numerical_output_1_loss: 1.7078 - numerical_output_2_loss: 1.1862 - numerical_output_3_loss: 1.3516 - numerical_output_4_loss: 0.4774 - numerical_output_5_loss: 0.0308 - numerical_output_6_loss: 0.0045 - units_loss: 0.8405 - numerical_output_0_accuracy: 0.3059 - numerical_output_1_accuracy: 0.4248 - numerical_output_2_accuracy: 0.6538 - numerical_output_3_accuracy: 0.6196 - numerical_output_4_accuracy: 0.8617 - numerical_output_5_accuracy: 0.9955 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.6337 - val_loss: 7.3773 - val_numerical_output_0_loss: 1.9303 - val_numerical_output_1_loss: 1.6514 - val_numerical_output_2_loss: 1.1746 - val_numerical_output_3_loss: 1.3068 - val_numerical_output_4_loss: 0.4612 - val_numerical_output_5_loss: 0.0292 - val_numerical_output_6_loss: 0.0069 - val_units_loss: 0.8169 - val_numerical_output_0_accuracy: 0.3134 - val_numerical_output_1_accuracy: 0.4439 - val_numerical_output_2_accuracy: 0.6553 - val_numerical_output_3_accuracy: 0.6282 - val_numerical_output_4_accuracy: 0.8612 - val_numerical_output_5_accuracy: 0.9959 - val_numerical_output_6_accuracy: 0.9991 - val_units_accuracy: 0.6314 - lr: 2.0000e-07\n",
      "Epoch 32/100\n",
      "612/612 [==============================] - 217s 330ms/step - loss: 7.5443 - numerical_output_0_loss: 1.9519 - numerical_output_1_loss: 1.7011 - numerical_output_2_loss: 1.1861 - numerical_output_3_loss: 1.3517 - numerical_output_4_loss: 0.4818 - numerical_output_5_loss: 0.0281 - numerical_output_6_loss: 0.0043 - units_loss: 0.8393 - numerical_output_0_accuracy: 0.3029 - numerical_output_1_accuracy: 0.4250 - numerical_output_2_accuracy: 0.6564 - numerical_output_3_accuracy: 0.6195 - numerical_output_4_accuracy: 0.8598 - numerical_output_5_accuracy: 0.9958 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.6327 - val_loss: 7.3506 - val_numerical_output_0_loss: 1.9405 - val_numerical_output_1_loss: 1.6648 - val_numerical_output_2_loss: 1.1172 - val_numerical_output_3_loss: 1.3217 - val_numerical_output_4_loss: 0.4736 - val_numerical_output_5_loss: 0.0173 - val_numerical_output_6_loss: 3.8288e-04 - val_units_loss: 0.8150 - val_numerical_output_0_accuracy: 0.2987 - val_numerical_output_1_accuracy: 0.4283 - val_numerical_output_2_accuracy: 0.6742 - val_numerical_output_3_accuracy: 0.6236 - val_numerical_output_4_accuracy: 0.8598 - val_numerical_output_5_accuracy: 0.9977 - val_numerical_output_6_accuracy: 1.0000 - val_units_accuracy: 0.6255 - lr: 2.0000e-07\n",
      "Epoch 33/100\n",
      "612/612 [==============================] - 216s 329ms/step - loss: 7.5210 - numerical_output_0_loss: 1.9449 - numerical_output_1_loss: 1.6967 - numerical_output_2_loss: 1.1880 - numerical_output_3_loss: 1.3411 - numerical_output_4_loss: 0.4783 - numerical_output_5_loss: 0.0301 - numerical_output_6_loss: 0.0044 - units_loss: 0.8375 - numerical_output_0_accuracy: 0.3041 - numerical_output_1_accuracy: 0.4252 - numerical_output_2_accuracy: 0.6536 - numerical_output_3_accuracy: 0.6220 - numerical_output_4_accuracy: 0.8610 - numerical_output_5_accuracy: 0.9955 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.6320 - val_loss: 7.4075 - val_numerical_output_0_loss: 1.9384 - val_numerical_output_1_loss: 1.6815 - val_numerical_output_2_loss: 1.1540 - val_numerical_output_3_loss: 1.3200 - val_numerical_output_4_loss: 0.4690 - val_numerical_output_5_loss: 0.0260 - val_numerical_output_6_loss: 4.2399e-04 - val_units_loss: 0.8183 - val_numerical_output_0_accuracy: 0.3019 - val_numerical_output_1_accuracy: 0.4301 - val_numerical_output_2_accuracy: 0.6622 - val_numerical_output_3_accuracy: 0.6195 - val_numerical_output_4_accuracy: 0.8598 - val_numerical_output_5_accuracy: 0.9959 - val_numerical_output_6_accuracy: 1.0000 - val_units_accuracy: 0.6369 - lr: 2.0000e-07\n",
      "Epoch 34/100\n",
      "612/612 [==============================] - 219s 334ms/step - loss: 7.5305 - numerical_output_0_loss: 1.9512 - numerical_output_1_loss: 1.6958 - numerical_output_2_loss: 1.1872 - numerical_output_3_loss: 1.3418 - numerical_output_4_loss: 0.4828 - numerical_output_5_loss: 0.0286 - numerical_output_6_loss: 0.0040 - units_loss: 0.8391 - numerical_output_0_accuracy: 0.3025 - numerical_output_1_accuracy: 0.4263 - numerical_output_2_accuracy: 0.6532 - numerical_output_3_accuracy: 0.6216 - numerical_output_4_accuracy: 0.8598 - numerical_output_5_accuracy: 0.9957 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.6325 - val_loss: 7.3671 - val_numerical_output_0_loss: 1.9519 - val_numerical_output_1_loss: 1.6552 - val_numerical_output_2_loss: 1.1506 - val_numerical_output_3_loss: 1.3160 - val_numerical_output_4_loss: 0.4636 - val_numerical_output_5_loss: 0.0321 - val_numerical_output_6_loss: 4.0537e-04 - val_units_loss: 0.7972 - val_numerical_output_0_accuracy: 0.3010 - val_numerical_output_1_accuracy: 0.4389 - val_numerical_output_2_accuracy: 0.6581 - val_numerical_output_3_accuracy: 0.6287 - val_numerical_output_4_accuracy: 0.8608 - val_numerical_output_5_accuracy: 0.9949 - val_numerical_output_6_accuracy: 1.0000 - val_units_accuracy: 0.6475 - lr: 2.0000e-07\n",
      "Epoch 35/100\n",
      "612/612 [==============================] - 215s 328ms/step - loss: 7.5395 - numerical_output_0_loss: 1.9451 - numerical_output_1_loss: 1.7037 - numerical_output_2_loss: 1.1874 - numerical_output_3_loss: 1.3475 - numerical_output_4_loss: 0.4834 - numerical_output_5_loss: 0.0283 - numerical_output_6_loss: 0.0044 - units_loss: 0.8397 - numerical_output_0_accuracy: 0.3056 - numerical_output_1_accuracy: 0.4237 - numerical_output_2_accuracy: 0.6531 - numerical_output_3_accuracy: 0.6205 - numerical_output_4_accuracy: 0.8597 - numerical_output_5_accuracy: 0.9958 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.6331 - val_loss: 7.2743 - val_numerical_output_0_loss: 1.9385 - val_numerical_output_1_loss: 1.6637 - val_numerical_output_2_loss: 1.0997 - val_numerical_output_3_loss: 1.2843 - val_numerical_output_4_loss: 0.4504 - val_numerical_output_5_loss: 0.0234 - val_numerical_output_6_loss: 0.0040 - val_units_loss: 0.8104 - val_numerical_output_0_accuracy: 0.3047 - val_numerical_output_1_accuracy: 0.4338 - val_numerical_output_2_accuracy: 0.6806 - val_numerical_output_3_accuracy: 0.6356 - val_numerical_output_4_accuracy: 0.8732 - val_numerical_output_5_accuracy: 0.9968 - val_numerical_output_6_accuracy: 0.9995 - val_units_accuracy: 0.6365 - lr: 2.0000e-07\n",
      "Epoch 36/100\n",
      "612/612 [==============================] - 217s 331ms/step - loss: 7.5365 - numerical_output_0_loss: 1.9450 - numerical_output_1_loss: 1.7008 - numerical_output_2_loss: 1.1891 - numerical_output_3_loss: 1.3458 - numerical_output_4_loss: 0.4806 - numerical_output_5_loss: 0.0282 - numerical_output_6_loss: 0.0038 - units_loss: 0.8431 - numerical_output_0_accuracy: 0.3056 - numerical_output_1_accuracy: 0.4260 - numerical_output_2_accuracy: 0.6530 - numerical_output_3_accuracy: 0.6196 - numerical_output_4_accuracy: 0.8596 - numerical_output_5_accuracy: 0.9959 - numerical_output_6_accuracy: 0.9996 - units_accuracy: 0.6345 - val_loss: 7.3381 - val_numerical_output_0_loss: 1.9617 - val_numerical_output_1_loss: 1.6285 - val_numerical_output_2_loss: 1.1580 - val_numerical_output_3_loss: 1.2659 - val_numerical_output_4_loss: 0.4727 - val_numerical_output_5_loss: 0.0442 - val_numerical_output_6_loss: 0.0048 - val_units_loss: 0.8023 - val_numerical_output_0_accuracy: 0.3015 - val_numerical_output_1_accuracy: 0.4458 - val_numerical_output_2_accuracy: 0.6576 - val_numerical_output_3_accuracy: 0.6383 - val_numerical_output_4_accuracy: 0.8557 - val_numerical_output_5_accuracy: 0.9940 - val_numerical_output_6_accuracy: 0.9995 - val_units_accuracy: 0.6411 - lr: 2.0000e-07\n",
      "Epoch 37/100\n",
      "612/612 [==============================] - 215s 328ms/step - loss: 7.5383 - numerical_output_0_loss: 1.9482 - numerical_output_1_loss: 1.7000 - numerical_output_2_loss: 1.1878 - numerical_output_3_loss: 1.3469 - numerical_output_4_loss: 0.4872 - numerical_output_5_loss: 0.0291 - numerical_output_6_loss: 0.0044 - units_loss: 0.8348 - numerical_output_0_accuracy: 0.3019 - numerical_output_1_accuracy: 0.4257 - numerical_output_2_accuracy: 0.6551 - numerical_output_3_accuracy: 0.6212 - numerical_output_4_accuracy: 0.8597 - numerical_output_5_accuracy: 0.9957 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.6372 - val_loss: 7.3330 - val_numerical_output_0_loss: 1.9101 - val_numerical_output_1_loss: 1.6755 - val_numerical_output_2_loss: 1.0929 - val_numerical_output_3_loss: 1.3184 - val_numerical_output_4_loss: 0.4826 - val_numerical_output_5_loss: 0.0248 - val_numerical_output_6_loss: 3.7393e-04 - val_units_loss: 0.8284 - val_numerical_output_0_accuracy: 0.3199 - val_numerical_output_1_accuracy: 0.4269 - val_numerical_output_2_accuracy: 0.6834 - val_numerical_output_3_accuracy: 0.6241 - val_numerical_output_4_accuracy: 0.8603 - val_numerical_output_5_accuracy: 0.9949 - val_numerical_output_6_accuracy: 1.0000 - val_units_accuracy: 0.6305 - lr: 2.0000e-07\n",
      "Epoch 38/100\n",
      "612/612 [==============================] - 217s 331ms/step - loss: 7.5248 - numerical_output_0_loss: 1.9509 - numerical_output_1_loss: 1.6921 - numerical_output_2_loss: 1.1841 - numerical_output_3_loss: 1.3414 - numerical_output_4_loss: 0.4798 - numerical_output_5_loss: 0.0301 - numerical_output_6_loss: 0.0044 - units_loss: 0.8420 - numerical_output_0_accuracy: 0.3023 - numerical_output_1_accuracy: 0.4292 - numerical_output_2_accuracy: 0.6545 - numerical_output_3_accuracy: 0.6237 - numerical_output_4_accuracy: 0.8605 - numerical_output_5_accuracy: 0.9955 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.6329 - val_loss: 7.3751 - val_numerical_output_0_loss: 1.9358 - val_numerical_output_1_loss: 1.6675 - val_numerical_output_2_loss: 1.1409 - val_numerical_output_3_loss: 1.2854 - val_numerical_output_4_loss: 0.4566 - val_numerical_output_5_loss: 0.0344 - val_numerical_output_6_loss: 0.0085 - val_units_loss: 0.8459 - val_numerical_output_0_accuracy: 0.3001 - val_numerical_output_1_accuracy: 0.4292 - val_numerical_output_2_accuracy: 0.6585 - val_numerical_output_3_accuracy: 0.6319 - val_numerical_output_4_accuracy: 0.8603 - val_numerical_output_5_accuracy: 0.9949 - val_numerical_output_6_accuracy: 0.9991 - val_units_accuracy: 0.6218 - lr: 2.0000e-07\n",
      "Epoch 39/100\n",
      "612/612 [==============================] - 216s 329ms/step - loss: 7.5210 - numerical_output_0_loss: 1.9465 - numerical_output_1_loss: 1.6998 - numerical_output_2_loss: 1.1805 - numerical_output_3_loss: 1.3438 - numerical_output_4_loss: 0.4803 - numerical_output_5_loss: 0.0280 - numerical_output_6_loss: 0.0042 - units_loss: 0.8379 - numerical_output_0_accuracy: 0.3036 - numerical_output_1_accuracy: 0.4257 - numerical_output_2_accuracy: 0.6563 - numerical_output_3_accuracy: 0.6215 - numerical_output_4_accuracy: 0.8605 - numerical_output_5_accuracy: 0.9958 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.6323 - val_loss: 7.3625 - val_numerical_output_0_loss: 1.9249 - val_numerical_output_1_loss: 1.6446 - val_numerical_output_2_loss: 1.1781 - val_numerical_output_3_loss: 1.2780 - val_numerical_output_4_loss: 0.4712 - val_numerical_output_5_loss: 0.0348 - val_numerical_output_6_loss: 4.0505e-04 - val_units_loss: 0.8305 - val_numerical_output_0_accuracy: 0.3015 - val_numerical_output_1_accuracy: 0.4338 - val_numerical_output_2_accuracy: 0.6558 - val_numerical_output_3_accuracy: 0.6245 - val_numerical_output_4_accuracy: 0.8511 - val_numerical_output_5_accuracy: 0.9945 - val_numerical_output_6_accuracy: 1.0000 - val_units_accuracy: 0.6245 - lr: 2.0000e-07\n",
      "Epoch 40/100\n",
      "612/612 [==============================] - 217s 331ms/step - loss: 7.5261 - numerical_output_0_loss: 1.9478 - numerical_output_1_loss: 1.6966 - numerical_output_2_loss: 1.1867 - numerical_output_3_loss: 1.3405 - numerical_output_4_loss: 0.4808 - numerical_output_5_loss: 0.0285 - numerical_output_6_loss: 0.0045 - units_loss: 0.8408 - numerical_output_0_accuracy: 0.3062 - numerical_output_1_accuracy: 0.4273 - numerical_output_2_accuracy: 0.6537 - numerical_output_3_accuracy: 0.6230 - numerical_output_4_accuracy: 0.8599 - numerical_output_5_accuracy: 0.9958 - numerical_output_6_accuracy: 0.9995 - units_accuracy: 0.6341 - val_loss: 7.3168 - val_numerical_output_0_loss: 1.9180 - val_numerical_output_1_loss: 1.6799 - val_numerical_output_2_loss: 1.0898 - val_numerical_output_3_loss: 1.3082 - val_numerical_output_4_loss: 0.4613 - val_numerical_output_5_loss: 0.0324 - val_numerical_output_6_loss: 0.0048 - val_units_loss: 0.8223 - val_numerical_output_0_accuracy: 0.3143 - val_numerical_output_1_accuracy: 0.4301 - val_numerical_output_2_accuracy: 0.6852 - val_numerical_output_3_accuracy: 0.6273 - val_numerical_output_4_accuracy: 0.8649 - val_numerical_output_5_accuracy: 0.9954 - val_numerical_output_6_accuracy: 0.9995 - val_units_accuracy: 0.6291 - lr: 2.0000e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x727c982986a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset,\n",
    "          validation_data=val_dataset, \n",
    "          epochs=100,\n",
    "          callbacks=[checkpoint_callback, lr_scheduler_callback, early_stopping_callback, reduce_lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(model\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 10\n",
    "# Ensure tokenized_input[0].ids and tokenized_input[0].attention_mask are numpy arrays or tensors\n",
    "input_ids = tokenized_input[id].ids\n",
    "attention_mask = tokenized_input[id].attention_mask\n",
    "\n",
    "# Convert to tensors if they are not already\n",
    "input_ids = tf.convert_to_tensor(input_ids, dtype=tf.int32)\n",
    "attention_mask = tf.convert_to_tensor(attention_mask, dtype=tf.int32)\n",
    "\n",
    "# Add batch dimension\n",
    "input_ids = tf.expand_dims(input_ids, axis=0)\n",
    "attention_mask = tf.expand_dims(attention_mask, axis=0)\n",
    "\n",
    "# Read and preprocess the image\n",
    "img_path = f'dataset/{image_paths[id]}.jpg'  # Replace with the correct path to your image\n",
    "img = tf.io.read_file(img_path)\n",
    "img = tf.image.decode_jpeg(img, channels=3)\n",
    "img = tf.image.resize(img, (224, 224))\n",
    "img = img / 255.0  # Normalize the image to [0, 1]\n",
    "\n",
    "# Add batch dimension to the image\n",
    "img = tf.expand_dims(img, axis=0)\n",
    "\n",
    "# Make the prediction\n",
    "predictions = model.predict([img, input_ids, attention_mask])\n",
    "\n",
    "\n",
    "scaler =  MinMaxScaler(feature_range=(0, 100))\n",
    "numeric_value = data['numeric_value']\n",
    "numeric_value = np.array(numeric_value).reshape(-1, 1)\n",
    "numeric_value = scaler.fit_transform(numeric_value)\n",
    "numerical_value = predictions[0][0][0]\n",
    "# Scale the numerical value back to its original range\n",
    "original_numerical_value = scaler.inverse_transform([[numerical_value]])[0][0]\n",
    "\n",
    "reverse = tf.keras.layers.StringLookup(vocabulary=string_lookup.get_vocabulary(), invert=True)\n",
    "unit_probabilities = predictions[1][0]\n",
    "predicted_unit_index = tf.argmax(unit_probabilities).numpy()\n",
    "print(\"Predicted Unit Index:\", image_paths[id])\n",
    "print(\"Predicted Unit Index:\", reverse(predicted_unit_index))\n",
    "print(\"Original Numerical Value:\", original_numerical_value)\n",
    "# Print the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
